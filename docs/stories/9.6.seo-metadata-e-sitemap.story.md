---
status: drafted
priority: medium
estimate: S
story_id: "9.6"
epic: "Epic 9 - Vetrina Pubblica e Lead Capture"
---

# Story 9.6: SEO, Metadata e Sitemap

**As a** Business owner, **I want** public pages optimized for search engines, **so that** potential customers can discover services organically.

## Acceptance Criteria

### AC-1
_Derived from epic-details AC-1._
**Given** the public routes `/`, `/servizi/sostituzione-display`, `/contatti`, `/faq`, and `/richiedi-preventivo` are rendered by `App` with pathname-aware content
**When** an anonymous visitor opens each route and inspects document head metadata
**Then** the page head contains route-specific values with exact titles `Gestionale Riparazioni | Assistenza dispositivi`, `Sostituzione display | Gestionale Riparazioni`, `Contatti | Gestionale Riparazioni`, `FAQ | Gestionale Riparazioni`, `Richiedi preventivo | Gestionale Riparazioni`, and each route has a non-empty `<meta name="description">` text tailored to that page

### AC-2
_Derived from epic-details AC-2._
**Given** service slug `sostituzione-display` is active and the visitor opens `/servizi/sostituzione-display`
**When** service detail metadata is resolved for SEO/social preview using base URL from env `PUBLIC_SITE_URL` (fallback `http://localhost:5173`)
**Then** the page sets canonical URL `{baseUrl}/servizi/sostituzione-display` and Open Graph tags `og:title="Sostituzione display | Gestionale Riparazioni"`, `og:description` containing `Diagnosi avanzata e sostituzione display`, `og:type="website"`, and `og:url` equal to the canonical URL

### AC-3
_Derived from epic-details AC-3._
**Given** active public service slugs are exposed by backend catalog data and include `sostituzione-display` while inactive `riparazione-legacy` exists in catalog but is not active
**When** a client requests `GET /sitemap.xml`
**Then** response is HTTP `200` with `Content-Type: application/xml`, XML `<urlset>` includes `loc` for `/`, `/contatti`, `/faq`, `/richiedi-preventivo`, `/servizi/sostituzione-display`, and does not include `/servizi/riparazione-legacy`

### AC-4
_Derived from epic-details AC-4._
**Given** SEO crawler directives are served from backend root routes and base URL is resolved from env `PUBLIC_SITE_URL` (fallback `http://localhost:5173`)
**When** a client requests `GET /robots.txt`
**Then** response is HTTP `200`, `Content-Type: text/plain`, and body contains exact directives `User-agent: *`, `Allow: /`, and `Sitemap: {baseUrl}/sitemap.xml`

## Target Modules

- `packages/frontend/src/App.tsx`
- `packages/frontend/index.html`
- `packages/backend/src/routes/seo.ts` (new)
- `packages/backend/src/index.ts`
- `packages/backend/src/services/anagrafiche-service.ts`
- `packages/frontend/src/__tests__/public-seo-metadata.atdd.spec.ts` (new)
- `packages/backend/src/__tests__/public-seo-routes.atdd.spec.ts` (new)

## Task Breakdown

- [x] Task 1 (AC-1, AC-2): extend `packages/frontend/src/App.tsx` with route-level metadata map (title, description, canonical, open-graph) and deterministic head update utilities that react to `path`.
- [x] Task 2 (AC-1): update `packages/frontend/index.html` baseline metadata defaults so non-routed bootstrap still has valid title/description.
- [x] Task 3 (AC-3): extend `packages/backend/src/services/anagrafiche-service.ts` with a dedicated helper to return active public service slugs for sitemap generation.
- [x] Task 4 (AC-3, AC-4): create `packages/backend/src/routes/seo.ts` exposing `GET /sitemap.xml` and `GET /robots.txt` with correct content-type, XML/text payload, and base URL resolution via `PUBLIC_SITE_URL` fallback.
- [x] Task 5 (AC-3, AC-4): register SEO routes in `packages/backend/src/index.ts` at root-level paths (`/sitemap.xml`, `/robots.txt`) without `/api` prefix.
- [x] Task 6 (AC-1, AC-2): add `packages/frontend/src/__tests__/public-seo-metadata.atdd.spec.ts` covering unique title/description per page and canonical/OG tags on service detail.
- [x] Task 7 (AC-3, AC-4): add `packages/backend/src/__tests__/public-seo-routes.atdd.spec.ts` validating sitemap content (public routes + active slugs only) and robots policy with sitemap reference.
